{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "4                        88.726562   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "4                                      40.672225   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "4                                    0.600866   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "4                             1.123492                   1.178930   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "4                                11.468720   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "4                             14.269573                     252.567306   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('pulsar_stars.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target_class', ylabel='count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target_class', ylabel='count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVAElEQVR4nO3dfZBdd33f8fcHCWQ74ACjtXElgRRXkMiUJ28dFxqGxG2sNomlpnVGnhBrwB211IWECQSrTOpOO+p4CikFgplRwFhOGbsqT1baMcFR6rgpBrF+iiwbFxUTa7FiLZAEh6YCmW//uD/DZX1XZy107135vl8zd/bc7/mdc76zI+mj85yqQpKk43nGuBuQJC19hoUkqZNhIUnqZFhIkjoZFpKkTsvH3cCwrFy5stauXTvuNiTplHLnnXd+raqm5teftmGxdu1aZmZmxt2GJJ1SkvzpoLqHoSRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktRpaGGR5LokR5LcN6/+5iQPJjmQ5D/01bcnOdjmXdxXPz/J/jbvfUkyrJ4lSYMNc8/iemBjfyHJTwObgJdV1XnAu1t9A7AFOK8tc22SZW2xDwLbgPXt8wPrlCQN39Du4K6q25OsnVd+E3BNVR1tY460+ibgplZ/KMlB4IIkXwHOrKo7AJLcAGwGbhlW3084/+03DHsTOgXd+a7Lx92CNBajPmfxYuCnknw+yR8l+dutvgo41DduttVWten59YGSbEsyk2Rmbm7uJLcuSZNr1GGxHHgecCHwdmB3Owcx6DxEHac+UFXtrKrpqpqemnrSc7AkSSdo1GExC3yievYB3wVWtvqavnGrgUdaffWAuiRphEYdFp8CfgYgyYuBZwFfA/YAW5KsSLKO3onsfVV1GHgsyYVtD+Ry4OYR9yxJE29oJ7iT3Ai8DliZZBa4GrgOuK5dTvttYGtVFXAgyW7gfuAYcGVVPd5W9SZ6V1adTu/E9tBPbkuSftAwr4a6bIFZr19g/A5gx4D6DPDSk9iaJOkp8g5uSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ2GFhZJrktypL0Vb/68tyWpJCv7atuTHEzyYJKL++rnJ9nf5r2vvV5VkjRCw9yzuB7YOL+YZA3w94GH+2obgC3AeW2Za5Msa7M/CGyj917u9YPWKUkarqGFRVXdDnxjwKz3AL8BVF9tE3BTVR2tqoeAg8AFSc4BzqyqO9q7um8ANg+rZ0nSYCM9Z5HkEuCrVXXvvFmrgEN932dbbVWbnl+XJI3Q8lFtKMkZwDuBnx00e0CtjlNfaBvb6B2y4oUvfOEJdClJGmSUexbnAuuAe5N8BVgN3JXkBfT2GNb0jV0NPNLqqwfUB6qqnVU1XVXTU1NTJ7l9SZpcIwuLqtpfVWdV1dqqWksvCF5VVX8G7AG2JFmRZB29E9n7quow8FiSC9tVUJcDN4+qZ0lSzzAvnb0RuAN4SZLZJFcsNLaqDgC7gfuBTwNXVtXjbfabgA/RO+n9f4BbhtWzJGmwoZ2zqKrLOuavnfd9B7BjwLgZ4KUntTlJ0lPiHdySpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROw3yt6nVJjiS5r6/2riRfTPInST6Z5Ll987YnOZjkwSQX99XPT7K/zXtfexe3JGmEhrlncT2wcV7tVuClVfUy4H8D2wGSbAC2AOe1Za5Nsqwt80FgG7C+feavU5I0ZEMLi6q6HfjGvNpnqupY+/o5YHWb3gTcVFVHq+oh4CBwQZJzgDOr6o6qKuAGYPOwepYkDTbOcxZvBG5p06uAQ33zZlttVZueXx8oybYkM0lm5ubmTnK7kjS5xhIWSd4JHAM++kRpwLA6Tn2gqtpZVdNVNT01NfXDNypJAmD5qDeYZCvw88BF7dAS9PYY1vQNWw080uqrB9QlSSM00j2LJBuBdwCXVNX/7Zu1B9iSZEWSdfROZO+rqsPAY0kubFdBXQ7cPMqeJUlD3LNIciPwOmBlklnganpXP60Abm1XwH6uqv55VR1Ishu4n97hqSur6vG2qjfRu7LqdHrnOG5BkjRSQwuLqrpsQPnDxxm/A9gxoD4DvPQktiZJeoq8g1uS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktRpaGGR5LokR5Lc11d7fpJbk3yp/Xxe37ztSQ4meTDJxX3185Psb/Pe197FLUkaoWHuWVwPbJxXuwrYW1Xrgb3tO0k2AFuA89oy1yZZ1pb5ILANWN8+89cpSRqyoYVFVd0OfGNeeROwq03vAjb31W+qqqNV9RBwELggyTnAmVV1R1UVcEPfMpKkERn1OYuzq+owQPt5VquvAg71jZtttVVten59oCTbkswkmZmbmzupjUvSJFsqJ7gHnYeo49QHqqqdVTVdVdNTU1MnrTlJmnSjDotH26El2s8jrT4LrOkbtxp4pNVXD6hLkkZo1GGxB9japrcCN/fVtyRZkWQdvRPZ+9qhqseSXNiugrq8bxlJ0ogsH9aKk9wIvA5YmWQWuBq4Btid5ArgYeBSgKo6kGQ3cD9wDLiyqh5vq3oTvSurTgduaR9J0ggNLSyq6rIFZl20wPgdwI4B9RngpSexNUnSU7RUTnBLkpYww0KS1MmwkCR1WlRYJNm7mJok6enpuCe4k5wGnEHviqbn8f2b5M4E/saQe5MkLRFdV0P9M+DX6AXDnXw/LL4JfGB4bUmSlpLjhkVVvRd4b5I3V9X7R9STJGmJWdR9FlX1/iSvBtb2L1NVNwypL0nSErKosEjyu8C5wD3AE3dWP/HIcEnS09xi7+CeBja0d0pIkibMYu+zuA94wTAbkSQtXYvds1gJ3J9kH3D0iWJVXTKUriRJS8piw+LfDLMJSdLSttirof5o2I1IkpauxV4N9Rjff53ps4BnAt+qqjOH1ZgkaelY7J7Fc/q/J9kMXDCMhiRJS88JPXW2qj4F/MzJbUWStFQt9jDUL/Z9fQa9+y5O+J6LJG8F/mlbx37gDfQeWPhf6N0l/hXgl6rqz9v47cAV9G4IfEtV/f6JbluS9NQt9mqoX+ibPkbvH/NNJ7LBJKuAt9C7ye+v27u3twAbgL1VdU2Sq4CrgHck2dDmn0fvgYZ/kOTFfe/oliQN2WLPWbxhCNs9Pcl36O1RPAJsB17X5u8CbgPeQS+Ubqqqo8BDSQ7SO19yx0nuSZK0gMW+/Gh1kk8mOZLk0SQfT7L6RDZYVV8F3g08DBwG/rKqPgOcXVWH25jDwFltkVXAob5VzLbaoD63JZlJMjM3N3ci7UmSBljsCe6PAHvoHQZaBfxeqz1l7SVKm4B1bX0/kuT1x1tkQG3g+ZKq2llV01U1PTU1dSLtSZIGWGxYTFXVR6rqWPtcD5zov8Z/D3ioquaq6jvAJ4BXA48mOQeg/TzSxs8Ca/qWX03vsJUkaUQWGxZfS/L6JMva5/XA109wmw8DFyY5I0mAi4AH6O25bG1jtgI3t+k9wJYkK5KsA9YD+05w25KkE7DYq6HeCPw28B56h4A+S+9y16esqj6f5GPAXfSurLob2Ak8G9id5Ap6gXJpG3+gXTF1fxt/pVdCSdJoLTYs/h2wte++h+fTO0n9xhPZaFVdDVw9r3yU3l7GoPE7gB0nsi1J0g9vsYehXvZEUABU1TeAVw6nJUnSUrPYsHhGu4oJ+N6exWL3SiRJp7jF/oP/W8Bn27mGAn4JDwtJ0sRY7B3cNySZoffwwAC/WFX3D7UzSdKSsehDSS0cDAhJmkAn9IhySdJkMSwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVKnsYRFkucm+ViSLyZ5IMnfSfL8JLcm+VL72f9I9O1JDiZ5MMnF4+hZkibZuPYs3gt8uqp+HHg5vXdwXwXsrar1wN72nSQbgC3AecBG4Noky8bStSRNqJGHRZIzgdcCHwaoqm9X1V8Am4BdbdguYHOb3gTcVFVHq+oh4CBwwSh7lqRJN449ix8D5oCPJLk7yYeS/AhwdlUdBmg/z2rjVwGH+pafbTVJ0oiMIyyWA68CPlhVrwS+RTvktIAMqNXAgcm2JDNJZubm5n74TiVJwHjCYhaYrarPt+8foxcejyY5B6D9PNI3fk3f8quBRwatuKp2VtV0VU1PTU0NpXlJmkQjD4uq+jPgUJKXtNJF9N7AtwfY2mpbgZvb9B5gS5IVSdYB64F9I2xZkibeol+repK9GfhokmcBXwbeQC+4die5AngYuBSgqg4k2U0vUI4BV1bV4+NpW5Im01jCoqruAaYHzLpogfE7gB3D7EmStDDv4JYkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUaW1gkWZbk7iT/rX1/fpJbk3yp/Xxe39jtSQ4meTDJxePqWZIm1Tj3LH4VeKDv+1XA3qpaD+xt30myAdgCnAdsBK5NsmzEvUrSRBtLWCRZDfwc8KG+8iZgV5veBWzuq99UVUer6iHgIHDBiFqVJDG+PYv/BPwG8N2+2tlVdRig/Tyr1VcBh/rGzbbakyTZlmQmyczc3NxJb1qSJtXIwyLJzwNHqurOxS4yoFaDBlbVzqqarqrpqampE+5RkvSDlo9hm68BLknyD4HTgDOT/Gfg0STnVNXhJOcAR9r4WWBN3/KrgUdG2rEkTbiR71lU1faqWl1Va+mduP7Dqno9sAfY2oZtBW5u03uALUlWJFkHrAf2jbhtSZpo49izWMg1wO4kVwAPA5cCVNWBJLuB+4FjwJVV9fj42pSkyTPWsKiq24Db2vTXgYsWGLcD2DGyxiRJP8A7uCVJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ1GHhZJ1iT5H0keSHIgya+2+vOT3JrkS+3n8/qW2Z7kYJIHk1w86p4ladKNY8/iGPDrVfUTwIXAlUk2AFcBe6tqPbC3fafN2wKcB2wErk2ybAx9S9LEGnlYVNXhqrqrTT8GPACsAjYBu9qwXcDmNr0JuKmqjlbVQ8BB4IKRNi1JE26s5yySrAVeCXweOLuqDkMvUICz2rBVwKG+xWZbbdD6tiWZSTIzNzc3tL4ladKMLSySPBv4OPBrVfXN4w0dUKtBA6tqZ1VNV9X01NTUyWhTkgQsH8dGkzyTXlB8tKo+0cqPJjmnqg4nOQc40uqzwJq+xVcDj4yuW2npefjf/q1xt6Al6IX/ev/Q1j2Oq6ECfBh4oKr+Y9+sPcDWNr0VuLmvviXJiiTrgPXAvlH1K0kaz57Fa4BfAfYnuafV/hVwDbA7yRXAw8ClAFV1IMlu4H56V1JdWVWPj7xrSZpgIw+LqvpjBp+HALhogWV2ADuG1pQk6bi8g1uS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTplAmLJBuTPJjkYJKrxt2PJE2SUyIskiwDPgD8A2ADcFmSDePtSpImxykRFsAFwMGq+nJVfRu4Cdg05p4kaWIsH3cDi7QKONT3fRb4yfmDkmwDtrWvf5XkwRH0NglWAl8bdxNLQd69ddwt6Mn88/mEq3My1vKiQcVTJSwG/QbqSYWqncDO4bczWZLMVNX0uPuQBvHP52icKoehZoE1fd9XA4+MqRdJmjinSlh8AVifZF2SZwFbgD1j7kmSJsYpcRiqqo4l+ZfA7wPLgOuq6sCY25okHtrTUuafzxFI1ZMO/UuS9ANOlcNQkqQxMiwkSZ0MCx2Xj1nRUpXkuiRHktw37l4mgWGhBfmYFS1x1wMbx93EpDAsdDw+ZkVLVlXdDnxj3H1MCsNCxzPoMSurxtSLpDEyLHQ8i3rMiqSnP8NCx+NjViQBhoWOz8esSAIMCx1HVR0DnnjMygPAbh+zoqUiyY3AHcBLkswmuWLcPT2d+bgPSVIn9ywkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQhMryXOT/IsRbGfziTytN8laH7+tpcKw0CR7LrDosEjPifyd2UzvEe/SKcuw0CS7Bjg3yT1J3pNkb5K7kuxPsgm+97/7B5JcC9wFrEnym0m+mOTWJDcmeVsbe26STye5M8n/TPLjSV4NXAK8q23n3EGNJPmbSf4gyb2th3PnzV/b1nlX+7y61c9Jcntb931JfirJsiTXt+/7k7x1iL9DTYqq8uNnIj/AWuC+Nr0cOLNNrwQO0nvq7lrgu8CFbd40cA9wOvAc4EvA29q8vcD6Nv2TwB+26euBf9LRy+eBf9SmTwPOmNffGcBpbXo9MNOmfx14Z5te1no6H7i1b93PHffv2s+p/1l+skJHOsUF+PdJXksvHFYBZ7d5f1pVn2vTfxe4uar+GiDJ77WfzwZeDfzX5HtPdl+xqA0nzwFWVdUnAarq/7V6/7BnAr+d5BXA48CLW/0LwHVJngl8qqruSfJl4MeSvB/478BnFvtLkBbiYSip55eBKeD8qnoF8Ci9/+EDfKtv3KB3fEDv79JfVNUr+j4/schtL7TOfm9tPb2c3t7Ns+B7b4t7LfBV4HeTXF5Vf97G3QZcCXxokX1ICzIsNMkeo3fYBuBHgSNV9Z0kPw28aIFl/hj4hSSntb2JnwOoqm8CDyW5FL53MvzlA7bzJG3Z2SSb27Irkpwxb9iPAoer6rvAr9A75ESSF7W+fwf4MPCqJCuBZ1TVx4HfBF61uF+HtDDDQhOrqr4O/K92eeorgOkkM/T2Mr64wDJfoPdOj3uBTwAzwF+22b8MXJHkXuAA339f+U3A25PcvdAJbnoB8JYkfwJ8FnjBvPnXAluTfI7eIagn9nZeB9yT5G7gHwPvpXcI7bYk99A7X7K963chdfER5dJTlOTZVfVX7X//twPbququcfclDZMnuKWnbme7ye40YJdBoUngnoU0Qkk+ALxmXvm9VfWRcfQjLZZhIUnq5AluSVInw0KS1MmwkCR1MiwkSZ3+P+4OyDuinw03AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred=logreg.predict(X_test)\n",
    "\n",
    "score_imbalanced=roc_auc_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96378784393724"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>vae oversampling</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority and Majority class are:  1 0\n",
      "Rows of the Org min 8\n",
      "MIN,MAJ,Desired (1457, 8) (14651, 8) 13194\n",
      "Train Epoch: 1 [0/1457 (0%)]\tLoss: 5.570508\n",
      "Train Epoch: 1 [10/1457 (1%)]\tLoss: 5.229959\n",
      "Train Epoch: 1 [20/1457 (1%)]\tLoss: 4.518190\n",
      "Train Epoch: 1 [30/1457 (2%)]\tLoss: 4.393605\n",
      "Train Epoch: 1 [40/1457 (3%)]\tLoss: 4.176116\n",
      "Train Epoch: 1 [50/1457 (3%)]\tLoss: 5.249683\n",
      "Train Epoch: 1 [60/1457 (4%)]\tLoss: 4.729216\n",
      "Train Epoch: 1 [70/1457 (5%)]\tLoss: 4.582911\n",
      "Train Epoch: 1 [80/1457 (5%)]\tLoss: 4.248406\n",
      "Train Epoch: 1 [90/1457 (6%)]\tLoss: 4.104414\n",
      "Train Epoch: 1 [100/1457 (7%)]\tLoss: 3.946732\n",
      "Train Epoch: 1 [110/1457 (8%)]\tLoss: 4.392620\n",
      "Train Epoch: 1 [120/1457 (8%)]\tLoss: 3.967868\n",
      "Train Epoch: 1 [130/1457 (9%)]\tLoss: 4.469131\n",
      "Train Epoch: 1 [140/1457 (10%)]\tLoss: 4.118847\n",
      "Train Epoch: 1 [150/1457 (10%)]\tLoss: 3.986151\n",
      "Train Epoch: 1 [160/1457 (11%)]\tLoss: 5.226358\n",
      "Train Epoch: 1 [170/1457 (12%)]\tLoss: 4.199789\n",
      "Train Epoch: 1 [180/1457 (12%)]\tLoss: 4.275544\n",
      "Train Epoch: 1 [190/1457 (13%)]\tLoss: 3.970207\n",
      "Train Epoch: 1 [200/1457 (14%)]\tLoss: 3.721302\n",
      "Train Epoch: 1 [210/1457 (14%)]\tLoss: 4.047496\n",
      "Train Epoch: 1 [220/1457 (15%)]\tLoss: 4.445374\n",
      "Train Epoch: 1 [230/1457 (16%)]\tLoss: 4.753170\n",
      "Train Epoch: 1 [240/1457 (16%)]\tLoss: 3.924423\n",
      "Train Epoch: 1 [250/1457 (17%)]\tLoss: 4.087449\n",
      "Train Epoch: 1 [260/1457 (18%)]\tLoss: 3.913856\n",
      "Train Epoch: 1 [270/1457 (19%)]\tLoss: 4.535048\n",
      "Train Epoch: 1 [280/1457 (19%)]\tLoss: 4.106025\n",
      "Train Epoch: 1 [290/1457 (20%)]\tLoss: 3.860692\n",
      "Train Epoch: 1 [300/1457 (21%)]\tLoss: 4.069022\n",
      "Train Epoch: 1 [310/1457 (21%)]\tLoss: 4.297410\n",
      "Train Epoch: 1 [320/1457 (22%)]\tLoss: 4.738840\n",
      "Train Epoch: 1 [330/1457 (23%)]\tLoss: 3.539298\n",
      "Train Epoch: 1 [340/1457 (23%)]\tLoss: 3.883334\n",
      "Train Epoch: 1 [350/1457 (24%)]\tLoss: 4.339434\n",
      "Train Epoch: 1 [360/1457 (25%)]\tLoss: 5.028350\n",
      "Train Epoch: 1 [370/1457 (25%)]\tLoss: 3.902462\n",
      "Train Epoch: 1 [380/1457 (26%)]\tLoss: 3.747372\n",
      "Train Epoch: 1 [390/1457 (27%)]\tLoss: 3.768730\n",
      "Train Epoch: 1 [400/1457 (27%)]\tLoss: 4.808621\n",
      "Train Epoch: 1 [410/1457 (28%)]\tLoss: 4.586806\n",
      "Train Epoch: 1 [420/1457 (29%)]\tLoss: 4.226614\n",
      "Train Epoch: 1 [430/1457 (30%)]\tLoss: 4.501623\n",
      "Train Epoch: 1 [440/1457 (30%)]\tLoss: 3.677436\n",
      "Train Epoch: 1 [450/1457 (31%)]\tLoss: 3.988178\n",
      "Train Epoch: 1 [460/1457 (32%)]\tLoss: 3.829198\n",
      "Train Epoch: 1 [470/1457 (32%)]\tLoss: 4.080070\n",
      "Train Epoch: 1 [480/1457 (33%)]\tLoss: 3.923804\n",
      "Train Epoch: 1 [490/1457 (34%)]\tLoss: 3.741776\n",
      "Train Epoch: 1 [500/1457 (34%)]\tLoss: 3.894561\n",
      "Train Epoch: 1 [510/1457 (35%)]\tLoss: 4.201577\n",
      "Train Epoch: 1 [520/1457 (36%)]\tLoss: 4.061520\n",
      "Train Epoch: 1 [530/1457 (36%)]\tLoss: 3.810936\n",
      "Train Epoch: 1 [540/1457 (37%)]\tLoss: 4.284854\n",
      "Train Epoch: 1 [550/1457 (38%)]\tLoss: 4.168928\n",
      "Train Epoch: 1 [560/1457 (38%)]\tLoss: 3.804609\n",
      "Train Epoch: 1 [570/1457 (39%)]\tLoss: 4.028832\n",
      "Train Epoch: 1 [580/1457 (40%)]\tLoss: 4.042401\n",
      "Train Epoch: 1 [590/1457 (40%)]\tLoss: 4.155108\n",
      "Train Epoch: 1 [600/1457 (41%)]\tLoss: 3.858922\n",
      "Train Epoch: 1 [610/1457 (42%)]\tLoss: 3.905842\n",
      "Train Epoch: 1 [620/1457 (43%)]\tLoss: 3.674392\n",
      "Train Epoch: 1 [630/1457 (43%)]\tLoss: 3.933832\n",
      "Train Epoch: 1 [640/1457 (44%)]\tLoss: 3.602406\n",
      "Train Epoch: 1 [650/1457 (45%)]\tLoss: 3.837863\n",
      "Train Epoch: 1 [660/1457 (45%)]\tLoss: 4.226096\n",
      "Train Epoch: 1 [670/1457 (46%)]\tLoss: 4.449259\n",
      "Train Epoch: 1 [680/1457 (47%)]\tLoss: 3.764755\n",
      "Train Epoch: 1 [690/1457 (47%)]\tLoss: 4.125036\n",
      "Train Epoch: 1 [700/1457 (48%)]\tLoss: 4.088220\n",
      "Train Epoch: 1 [710/1457 (49%)]\tLoss: 4.569975\n",
      "Train Epoch: 1 [720/1457 (49%)]\tLoss: 4.587788\n",
      "Train Epoch: 1 [730/1457 (50%)]\tLoss: 4.145240\n",
      "Train Epoch: 1 [740/1457 (51%)]\tLoss: 3.736943\n",
      "Train Epoch: 1 [750/1457 (51%)]\tLoss: 3.872449\n",
      "Train Epoch: 1 [760/1457 (52%)]\tLoss: 4.852506\n",
      "Train Epoch: 1 [770/1457 (53%)]\tLoss: 3.894065\n",
      "Train Epoch: 1 [780/1457 (54%)]\tLoss: 3.956972\n",
      "Train Epoch: 1 [790/1457 (54%)]\tLoss: 4.126144\n",
      "Train Epoch: 1 [800/1457 (55%)]\tLoss: 4.344759\n",
      "Train Epoch: 1 [810/1457 (56%)]\tLoss: 4.623340\n",
      "Train Epoch: 1 [820/1457 (56%)]\tLoss: 3.882685\n",
      "Train Epoch: 1 [830/1457 (57%)]\tLoss: 4.089437\n",
      "Train Epoch: 1 [840/1457 (58%)]\tLoss: 5.380820\n",
      "Train Epoch: 1 [850/1457 (58%)]\tLoss: 4.037926\n",
      "Train Epoch: 1 [860/1457 (59%)]\tLoss: 4.204246\n",
      "Train Epoch: 1 [870/1457 (60%)]\tLoss: 4.577391\n",
      "Train Epoch: 1 [880/1457 (60%)]\tLoss: 4.018449\n",
      "Train Epoch: 1 [890/1457 (61%)]\tLoss: 4.703356\n",
      "Train Epoch: 1 [900/1457 (62%)]\tLoss: 3.758698\n",
      "Train Epoch: 1 [910/1457 (62%)]\tLoss: 3.803104\n",
      "Train Epoch: 1 [920/1457 (63%)]\tLoss: 4.032742\n",
      "Train Epoch: 1 [930/1457 (64%)]\tLoss: 4.013642\n",
      "Train Epoch: 1 [940/1457 (65%)]\tLoss: 3.985658\n",
      "Train Epoch: 1 [950/1457 (65%)]\tLoss: 4.079136\n",
      "Train Epoch: 1 [960/1457 (66%)]\tLoss: 4.417026\n",
      "Train Epoch: 1 [970/1457 (67%)]\tLoss: 3.987276\n",
      "Train Epoch: 1 [980/1457 (67%)]\tLoss: 3.922978\n",
      "Train Epoch: 1 [990/1457 (68%)]\tLoss: 3.826560\n",
      "Train Epoch: 1 [1000/1457 (69%)]\tLoss: 6.212926\n",
      "Train Epoch: 1 [1010/1457 (69%)]\tLoss: 4.322563\n",
      "Train Epoch: 1 [1020/1457 (70%)]\tLoss: 4.508926\n",
      "Train Epoch: 1 [1030/1457 (71%)]\tLoss: 3.665372\n",
      "Train Epoch: 1 [1040/1457 (71%)]\tLoss: 4.602975\n",
      "Train Epoch: 1 [1050/1457 (72%)]\tLoss: 3.912610\n",
      "Train Epoch: 1 [1060/1457 (73%)]\tLoss: 4.045000\n",
      "Train Epoch: 1 [1070/1457 (73%)]\tLoss: 3.904368\n",
      "Train Epoch: 1 [1080/1457 (74%)]\tLoss: 3.784101\n",
      "Train Epoch: 1 [1090/1457 (75%)]\tLoss: 4.144719\n",
      "Train Epoch: 1 [1100/1457 (75%)]\tLoss: 3.888435\n",
      "Train Epoch: 1 [1110/1457 (76%)]\tLoss: 4.165989\n",
      "Train Epoch: 1 [1120/1457 (77%)]\tLoss: 3.815596\n",
      "Train Epoch: 1 [1130/1457 (78%)]\tLoss: 4.022082\n",
      "Train Epoch: 1 [1140/1457 (78%)]\tLoss: 3.809496\n",
      "Train Epoch: 1 [1150/1457 (79%)]\tLoss: 4.489272\n",
      "Train Epoch: 1 [1160/1457 (80%)]\tLoss: 7.202763\n",
      "Train Epoch: 1 [1170/1457 (80%)]\tLoss: 5.023327\n",
      "Train Epoch: 1 [1180/1457 (81%)]\tLoss: 4.000497\n",
      "Train Epoch: 1 [1190/1457 (82%)]\tLoss: 4.245543\n",
      "Train Epoch: 1 [1200/1457 (82%)]\tLoss: 3.707449\n",
      "Train Epoch: 1 [1210/1457 (83%)]\tLoss: 3.971729\n",
      "Train Epoch: 1 [1220/1457 (84%)]\tLoss: 4.067122\n",
      "Train Epoch: 1 [1230/1457 (84%)]\tLoss: 3.793731\n",
      "Train Epoch: 1 [1240/1457 (85%)]\tLoss: 4.367823\n",
      "Train Epoch: 1 [1250/1457 (86%)]\tLoss: 3.912497\n",
      "Train Epoch: 1 [1260/1457 (86%)]\tLoss: 4.072601\n",
      "Train Epoch: 1 [1270/1457 (87%)]\tLoss: 4.194838\n",
      "Train Epoch: 1 [1280/1457 (88%)]\tLoss: 4.479784\n",
      "Train Epoch: 1 [1290/1457 (89%)]\tLoss: 3.887504\n",
      "Train Epoch: 1 [1300/1457 (89%)]\tLoss: 4.268459\n",
      "Train Epoch: 1 [1310/1457 (90%)]\tLoss: 3.698307\n",
      "Train Epoch: 1 [1320/1457 (91%)]\tLoss: 4.259872\n",
      "Train Epoch: 1 [1330/1457 (91%)]\tLoss: 4.223006\n",
      "Train Epoch: 1 [1340/1457 (92%)]\tLoss: 4.459630\n",
      "Train Epoch: 1 [1350/1457 (93%)]\tLoss: 3.933288\n",
      "Train Epoch: 1 [1360/1457 (93%)]\tLoss: 3.773195\n",
      "Train Epoch: 1 [1370/1457 (94%)]\tLoss: 4.115622\n",
      "Train Epoch: 1 [1380/1457 (95%)]\tLoss: 3.659521\n",
      "Train Epoch: 1 [1390/1457 (95%)]\tLoss: 4.069370\n",
      "Train Epoch: 1 [1400/1457 (96%)]\tLoss: 3.864267\n",
      "Train Epoch: 1 [1410/1457 (97%)]\tLoss: 3.765521\n",
      "Train Epoch: 1 [1420/1457 (97%)]\tLoss: 4.465541\n",
      "Train Epoch: 1 [1430/1457 (98%)]\tLoss: 4.441471\n",
      "Train Epoch: 1 [1440/1457 (99%)]\tLoss: 3.507039\n",
      "Train Epoch: 1 [1450/1457 (100%)]\tLoss: 4.256073\n",
      "====> Epoch: 1 Average loss: 4.1756\n",
      "Train Epoch: 2 [0/1457 (0%)]\tLoss: 4.091414\n",
      "Train Epoch: 2 [10/1457 (1%)]\tLoss: 4.589312\n",
      "Train Epoch: 2 [20/1457 (1%)]\tLoss: 4.259315\n",
      "Train Epoch: 2 [30/1457 (2%)]\tLoss: 3.788465\n",
      "Train Epoch: 2 [40/1457 (3%)]\tLoss: 3.934429\n",
      "Train Epoch: 2 [50/1457 (3%)]\tLoss: 6.310465\n",
      "Train Epoch: 2 [60/1457 (4%)]\tLoss: 4.634434\n",
      "Train Epoch: 2 [70/1457 (5%)]\tLoss: 4.557726\n",
      "Train Epoch: 2 [80/1457 (5%)]\tLoss: 3.794555\n",
      "Train Epoch: 2 [90/1457 (6%)]\tLoss: 3.995337\n",
      "Train Epoch: 2 [100/1457 (7%)]\tLoss: 4.527704\n",
      "Train Epoch: 2 [110/1457 (8%)]\tLoss: 3.968313\n",
      "Train Epoch: 2 [120/1457 (8%)]\tLoss: 3.997004\n",
      "Train Epoch: 2 [130/1457 (9%)]\tLoss: 4.233685\n",
      "Train Epoch: 2 [140/1457 (10%)]\tLoss: 4.198123\n",
      "Train Epoch: 2 [150/1457 (10%)]\tLoss: 4.227190\n",
      "Train Epoch: 2 [160/1457 (11%)]\tLoss: 4.502495\n",
      "Train Epoch: 2 [170/1457 (12%)]\tLoss: 4.322475\n",
      "Train Epoch: 2 [180/1457 (12%)]\tLoss: 4.185741\n",
      "Train Epoch: 2 [190/1457 (13%)]\tLoss: 3.912945\n",
      "Train Epoch: 2 [200/1457 (14%)]\tLoss: 3.862472\n",
      "Train Epoch: 2 [210/1457 (14%)]\tLoss: 4.050915\n",
      "Train Epoch: 2 [220/1457 (15%)]\tLoss: 4.533989\n",
      "Train Epoch: 2 [230/1457 (16%)]\tLoss: 4.313170\n",
      "Train Epoch: 2 [240/1457 (16%)]\tLoss: 4.347975\n",
      "Train Epoch: 2 [250/1457 (17%)]\tLoss: 3.927091\n",
      "Train Epoch: 2 [260/1457 (18%)]\tLoss: 3.859083\n",
      "Train Epoch: 2 [270/1457 (19%)]\tLoss: 4.140375\n",
      "Train Epoch: 2 [280/1457 (19%)]\tLoss: 4.168869\n",
      "Train Epoch: 2 [290/1457 (20%)]\tLoss: 4.038191\n",
      "Train Epoch: 2 [300/1457 (21%)]\tLoss: 4.575764\n",
      "Train Epoch: 2 [310/1457 (21%)]\tLoss: 3.817045\n",
      "Train Epoch: 2 [320/1457 (22%)]\tLoss: 5.039335\n",
      "Train Epoch: 2 [330/1457 (23%)]\tLoss: 4.174428\n",
      "Train Epoch: 2 [340/1457 (23%)]\tLoss: 3.788666\n",
      "Train Epoch: 2 [350/1457 (24%)]\tLoss: 4.593770\n",
      "Train Epoch: 2 [360/1457 (25%)]\tLoss: 3.862805\n",
      "Train Epoch: 2 [370/1457 (25%)]\tLoss: 3.972246\n",
      "Train Epoch: 2 [380/1457 (26%)]\tLoss: 3.879889\n",
      "Train Epoch: 2 [390/1457 (27%)]\tLoss: 4.187179\n",
      "Train Epoch: 2 [400/1457 (27%)]\tLoss: 4.076563\n",
      "Train Epoch: 2 [410/1457 (28%)]\tLoss: 3.420617\n",
      "Train Epoch: 2 [420/1457 (29%)]\tLoss: 4.566353\n",
      "Train Epoch: 2 [430/1457 (30%)]\tLoss: 4.065657\n",
      "Train Epoch: 2 [440/1457 (30%)]\tLoss: 3.647720\n",
      "Train Epoch: 2 [450/1457 (31%)]\tLoss: 3.903165\n",
      "Train Epoch: 2 [460/1457 (32%)]\tLoss: 4.023612\n",
      "Train Epoch: 2 [470/1457 (32%)]\tLoss: 4.166539\n",
      "Train Epoch: 2 [480/1457 (33%)]\tLoss: 3.879647\n",
      "Train Epoch: 2 [490/1457 (34%)]\tLoss: 3.920155\n",
      "Train Epoch: 2 [500/1457 (34%)]\tLoss: 3.907646\n",
      "Train Epoch: 2 [510/1457 (35%)]\tLoss: 4.446480\n",
      "Train Epoch: 2 [520/1457 (36%)]\tLoss: 3.957704\n",
      "Train Epoch: 2 [530/1457 (36%)]\tLoss: 4.324127\n",
      "Train Epoch: 2 [540/1457 (37%)]\tLoss: 4.569475\n",
      "Train Epoch: 2 [550/1457 (38%)]\tLoss: 4.324692\n",
      "Train Epoch: 2 [560/1457 (38%)]\tLoss: 3.734012\n",
      "Train Epoch: 2 [570/1457 (39%)]\tLoss: 3.996243\n",
      "Train Epoch: 2 [580/1457 (40%)]\tLoss: 4.196927\n",
      "Train Epoch: 2 [590/1457 (40%)]\tLoss: 3.915462\n",
      "Train Epoch: 2 [600/1457 (41%)]\tLoss: 3.868894\n",
      "Train Epoch: 2 [610/1457 (42%)]\tLoss: 3.840677\n",
      "Train Epoch: 2 [620/1457 (43%)]\tLoss: 3.752205\n",
      "Train Epoch: 2 [630/1457 (43%)]\tLoss: 3.891695\n",
      "Train Epoch: 2 [640/1457 (44%)]\tLoss: 4.010322\n",
      "Train Epoch: 2 [650/1457 (45%)]\tLoss: 3.960332\n",
      "Train Epoch: 2 [660/1457 (45%)]\tLoss: 4.136763\n",
      "Train Epoch: 2 [670/1457 (46%)]\tLoss: 4.327054\n",
      "Train Epoch: 2 [680/1457 (47%)]\tLoss: 3.716931\n",
      "Train Epoch: 2 [690/1457 (47%)]\tLoss: 4.049840\n",
      "Train Epoch: 2 [700/1457 (48%)]\tLoss: 3.907263\n",
      "Train Epoch: 2 [710/1457 (49%)]\tLoss: 4.220814\n",
      "Train Epoch: 2 [720/1457 (49%)]\tLoss: 5.800772\n",
      "Train Epoch: 2 [730/1457 (50%)]\tLoss: 4.081825\n",
      "Train Epoch: 2 [740/1457 (51%)]\tLoss: 4.046037\n",
      "Train Epoch: 2 [750/1457 (51%)]\tLoss: 4.097202\n",
      "Train Epoch: 2 [760/1457 (52%)]\tLoss: 4.677141\n",
      "Train Epoch: 2 [770/1457 (53%)]\tLoss: 3.957336\n",
      "Train Epoch: 2 [780/1457 (54%)]\tLoss: 4.088624\n",
      "Train Epoch: 2 [790/1457 (54%)]\tLoss: 4.314472\n",
      "Train Epoch: 2 [800/1457 (55%)]\tLoss: 3.943095\n",
      "Train Epoch: 2 [810/1457 (56%)]\tLoss: 4.697111\n",
      "Train Epoch: 2 [820/1457 (56%)]\tLoss: 4.575615\n",
      "Train Epoch: 2 [830/1457 (57%)]\tLoss: 3.851162\n",
      "Train Epoch: 2 [840/1457 (58%)]\tLoss: 4.492759\n",
      "Train Epoch: 2 [850/1457 (58%)]\tLoss: 4.269302\n",
      "Train Epoch: 2 [860/1457 (59%)]\tLoss: 3.987593\n",
      "Train Epoch: 2 [870/1457 (60%)]\tLoss: 4.308976\n",
      "Train Epoch: 2 [880/1457 (60%)]\tLoss: 4.415181\n",
      "Train Epoch: 2 [890/1457 (61%)]\tLoss: 4.461246\n",
      "Train Epoch: 2 [900/1457 (62%)]\tLoss: 3.816918\n",
      "Train Epoch: 2 [910/1457 (62%)]\tLoss: 4.001153\n",
      "Train Epoch: 2 [920/1457 (63%)]\tLoss: 3.986018\n",
      "Train Epoch: 2 [930/1457 (64%)]\tLoss: 4.067316\n",
      "Train Epoch: 2 [940/1457 (65%)]\tLoss: 4.548146\n",
      "Train Epoch: 2 [950/1457 (65%)]\tLoss: 4.003536\n",
      "Train Epoch: 2 [960/1457 (66%)]\tLoss: 4.297047\n",
      "Train Epoch: 2 [970/1457 (67%)]\tLoss: 4.443421\n",
      "Train Epoch: 2 [980/1457 (67%)]\tLoss: 3.924156\n",
      "Train Epoch: 2 [990/1457 (68%)]\tLoss: 3.699220\n",
      "Train Epoch: 2 [1000/1457 (69%)]\tLoss: 4.833757\n",
      "Train Epoch: 2 [1010/1457 (69%)]\tLoss: 4.326500\n",
      "Train Epoch: 2 [1020/1457 (70%)]\tLoss: 4.165065\n",
      "Train Epoch: 2 [1030/1457 (71%)]\tLoss: 3.700549\n",
      "Train Epoch: 2 [1040/1457 (71%)]\tLoss: 4.086844\n",
      "Train Epoch: 2 [1050/1457 (72%)]\tLoss: 3.964213\n",
      "Train Epoch: 2 [1060/1457 (73%)]\tLoss: 4.321270\n",
      "Train Epoch: 2 [1070/1457 (73%)]\tLoss: 3.733196\n",
      "Train Epoch: 2 [1080/1457 (74%)]\tLoss: 4.029319\n",
      "Train Epoch: 2 [1090/1457 (75%)]\tLoss: 4.094641\n",
      "Train Epoch: 2 [1100/1457 (75%)]\tLoss: 5.750826\n",
      "Train Epoch: 2 [1110/1457 (76%)]\tLoss: 4.237762\n",
      "Train Epoch: 2 [1120/1457 (77%)]\tLoss: 3.996200\n",
      "Train Epoch: 2 [1130/1457 (78%)]\tLoss: 4.303209\n",
      "Train Epoch: 2 [1140/1457 (78%)]\tLoss: 3.762331\n",
      "Train Epoch: 2 [1150/1457 (79%)]\tLoss: 4.405254\n",
      "Train Epoch: 2 [1160/1457 (80%)]\tLoss: 5.598249\n",
      "Train Epoch: 2 [1170/1457 (80%)]\tLoss: 4.605070\n",
      "Train Epoch: 2 [1180/1457 (81%)]\tLoss: 3.994365\n",
      "Train Epoch: 2 [1190/1457 (82%)]\tLoss: 4.316923\n",
      "Train Epoch: 2 [1200/1457 (82%)]\tLoss: 3.815401\n",
      "Train Epoch: 2 [1210/1457 (83%)]\tLoss: 3.634854\n",
      "Train Epoch: 2 [1220/1457 (84%)]\tLoss: 3.726013\n",
      "Train Epoch: 2 [1230/1457 (84%)]\tLoss: 3.966649\n",
      "Train Epoch: 2 [1240/1457 (85%)]\tLoss: 3.913660\n",
      "Train Epoch: 2 [1250/1457 (86%)]\tLoss: 3.863162\n",
      "Train Epoch: 2 [1260/1457 (86%)]\tLoss: 3.842654\n",
      "Train Epoch: 2 [1270/1457 (87%)]\tLoss: 4.405273\n",
      "Train Epoch: 2 [1280/1457 (88%)]\tLoss: 4.391261\n",
      "Train Epoch: 2 [1290/1457 (89%)]\tLoss: 3.741051\n",
      "Train Epoch: 2 [1300/1457 (89%)]\tLoss: 4.325717\n",
      "Train Epoch: 2 [1310/1457 (90%)]\tLoss: 3.718942\n",
      "Train Epoch: 2 [1320/1457 (91%)]\tLoss: 4.313542\n",
      "Train Epoch: 2 [1330/1457 (91%)]\tLoss: 4.347479\n",
      "Train Epoch: 2 [1340/1457 (92%)]\tLoss: 3.888348\n",
      "Train Epoch: 2 [1350/1457 (93%)]\tLoss: 3.860221\n",
      "Train Epoch: 2 [1360/1457 (93%)]\tLoss: 3.791654\n",
      "Train Epoch: 2 [1370/1457 (94%)]\tLoss: 3.740376\n",
      "Train Epoch: 2 [1380/1457 (95%)]\tLoss: 3.747771\n",
      "Train Epoch: 2 [1390/1457 (95%)]\tLoss: 4.033857\n",
      "Train Epoch: 2 [1400/1457 (96%)]\tLoss: 3.917417\n",
      "Train Epoch: 2 [1410/1457 (97%)]\tLoss: 3.758945\n",
      "Train Epoch: 2 [1420/1457 (97%)]\tLoss: 4.266351\n",
      "Train Epoch: 2 [1430/1457 (98%)]\tLoss: 4.224078\n",
      "Train Epoch: 2 [1440/1457 (99%)]\tLoss: 4.230210\n",
      "Train Epoch: 2 [1450/1457 (100%)]\tLoss: 4.351065\n",
      "====> Epoch: 2 Average loss: 4.1417\n",
      "Train Epoch: 3 [0/1457 (0%)]\tLoss: 4.005304\n",
      "Train Epoch: 3 [10/1457 (1%)]\tLoss: 4.465012\n",
      "Train Epoch: 3 [20/1457 (1%)]\tLoss: 4.215097\n",
      "Train Epoch: 3 [30/1457 (2%)]\tLoss: 3.656676\n",
      "Train Epoch: 3 [40/1457 (3%)]\tLoss: 4.051277\n",
      "Train Epoch: 3 [50/1457 (3%)]\tLoss: 5.930524\n",
      "Train Epoch: 3 [60/1457 (4%)]\tLoss: 4.639135\n",
      "Train Epoch: 3 [70/1457 (5%)]\tLoss: 4.555712\n",
      "Train Epoch: 3 [80/1457 (5%)]\tLoss: 4.781967\n",
      "Train Epoch: 3 [90/1457 (6%)]\tLoss: 4.093523\n",
      "Train Epoch: 3 [100/1457 (7%)]\tLoss: 3.938778\n",
      "Train Epoch: 3 [110/1457 (8%)]\tLoss: 3.933089\n",
      "Train Epoch: 3 [120/1457 (8%)]\tLoss: 3.916680\n",
      "Train Epoch: 3 [130/1457 (9%)]\tLoss: 4.251215\n",
      "Train Epoch: 3 [140/1457 (10%)]\tLoss: 4.490136\n",
      "Train Epoch: 3 [150/1457 (10%)]\tLoss: 4.040960\n",
      "Train Epoch: 3 [160/1457 (11%)]\tLoss: 4.640650\n",
      "Train Epoch: 3 [170/1457 (12%)]\tLoss: 4.202571\n",
      "Train Epoch: 3 [180/1457 (12%)]\tLoss: 4.003360\n",
      "Train Epoch: 3 [190/1457 (13%)]\tLoss: 3.908933\n",
      "Train Epoch: 3 [200/1457 (14%)]\tLoss: 3.931458\n",
      "Train Epoch: 3 [210/1457 (14%)]\tLoss: 3.981254\n",
      "Train Epoch: 3 [220/1457 (15%)]\tLoss: 4.890356\n",
      "Train Epoch: 3 [230/1457 (16%)]\tLoss: 5.202676\n",
      "Train Epoch: 3 [240/1457 (16%)]\tLoss: 4.656455\n",
      "Train Epoch: 3 [250/1457 (17%)]\tLoss: 4.045310\n",
      "Train Epoch: 3 [260/1457 (18%)]\tLoss: 3.761934\n",
      "Train Epoch: 3 [270/1457 (19%)]\tLoss: 4.329753\n",
      "Train Epoch: 3 [280/1457 (19%)]\tLoss: 4.171417\n",
      "Train Epoch: 3 [290/1457 (20%)]\tLoss: 3.824228\n",
      "Train Epoch: 3 [300/1457 (21%)]\tLoss: 4.697862\n",
      "Train Epoch: 3 [310/1457 (21%)]\tLoss: 3.884450\n",
      "Train Epoch: 3 [320/1457 (22%)]\tLoss: 4.833402\n",
      "Train Epoch: 3 [330/1457 (23%)]\tLoss: 4.009033\n",
      "Train Epoch: 3 [340/1457 (23%)]\tLoss: 3.944597\n",
      "Train Epoch: 3 [350/1457 (24%)]\tLoss: 4.341269\n",
      "Train Epoch: 3 [360/1457 (25%)]\tLoss: 4.923938\n",
      "Train Epoch: 3 [370/1457 (25%)]\tLoss: 4.027621\n",
      "Train Epoch: 3 [380/1457 (26%)]\tLoss: 4.342076\n",
      "Train Epoch: 3 [390/1457 (27%)]\tLoss: 3.834660\n",
      "Train Epoch: 3 [400/1457 (27%)]\tLoss: 4.265802\n",
      "Train Epoch: 3 [410/1457 (28%)]\tLoss: 4.888398\n",
      "Train Epoch: 3 [420/1457 (29%)]\tLoss: 4.268896\n",
      "Train Epoch: 3 [430/1457 (30%)]\tLoss: 3.889304\n",
      "Train Epoch: 3 [440/1457 (30%)]\tLoss: 3.522802\n",
      "Train Epoch: 3 [450/1457 (31%)]\tLoss: 3.950764\n",
      "Train Epoch: 3 [460/1457 (32%)]\tLoss: 3.789787\n",
      "Train Epoch: 3 [470/1457 (32%)]\tLoss: 4.053027\n",
      "Train Epoch: 3 [480/1457 (33%)]\tLoss: 3.963460\n",
      "Train Epoch: 3 [490/1457 (34%)]\tLoss: 3.745838\n",
      "Train Epoch: 3 [500/1457 (34%)]\tLoss: 3.864826\n",
      "Train Epoch: 3 [510/1457 (35%)]\tLoss: 4.460540\n",
      "Train Epoch: 3 [520/1457 (36%)]\tLoss: 4.179380\n",
      "Train Epoch: 3 [530/1457 (36%)]\tLoss: 3.908489\n",
      "Train Epoch: 3 [540/1457 (37%)]\tLoss: 4.650793\n",
      "Train Epoch: 3 [550/1457 (38%)]\tLoss: 4.463813\n",
      "Train Epoch: 3 [560/1457 (38%)]\tLoss: 3.779155\n",
      "Train Epoch: 3 [570/1457 (39%)]\tLoss: 3.748117\n",
      "Train Epoch: 3 [580/1457 (40%)]\tLoss: 4.132065\n",
      "Train Epoch: 3 [590/1457 (40%)]\tLoss: 4.748722\n",
      "Train Epoch: 3 [600/1457 (41%)]\tLoss: 3.839824\n",
      "Train Epoch: 3 [610/1457 (42%)]\tLoss: 3.980017\n",
      "Train Epoch: 3 [620/1457 (43%)]\tLoss: 4.033043\n",
      "Train Epoch: 3 [630/1457 (43%)]\tLoss: 3.831213\n",
      "Train Epoch: 3 [640/1457 (44%)]\tLoss: 3.685555\n",
      "Train Epoch: 3 [650/1457 (45%)]\tLoss: 3.645495\n",
      "Train Epoch: 3 [660/1457 (45%)]\tLoss: 4.254643\n",
      "Train Epoch: 3 [670/1457 (46%)]\tLoss: 4.280364\n",
      "Train Epoch: 3 [680/1457 (47%)]\tLoss: 3.965707\n",
      "Train Epoch: 3 [690/1457 (47%)]\tLoss: 4.115089\n",
      "Train Epoch: 3 [700/1457 (48%)]\tLoss: 3.987893\n",
      "Train Epoch: 3 [710/1457 (49%)]\tLoss: 3.949883\n",
      "Train Epoch: 3 [720/1457 (49%)]\tLoss: 4.763161\n",
      "Train Epoch: 3 [730/1457 (50%)]\tLoss: 4.488478\n",
      "Train Epoch: 3 [740/1457 (51%)]\tLoss: 3.884077\n",
      "Train Epoch: 3 [750/1457 (51%)]\tLoss: 3.874630\n",
      "Train Epoch: 3 [760/1457 (52%)]\tLoss: 4.228738\n",
      "Train Epoch: 3 [770/1457 (53%)]\tLoss: 4.023986\n",
      "Train Epoch: 3 [780/1457 (54%)]\tLoss: 3.956892\n",
      "Train Epoch: 3 [790/1457 (54%)]\tLoss: 4.098475\n",
      "Train Epoch: 3 [800/1457 (55%)]\tLoss: 4.441543\n",
      "Train Epoch: 3 [810/1457 (56%)]\tLoss: 4.486671\n",
      "Train Epoch: 3 [820/1457 (56%)]\tLoss: 4.470852\n",
      "Train Epoch: 3 [830/1457 (57%)]\tLoss: 3.883390\n",
      "Train Epoch: 3 [840/1457 (58%)]\tLoss: 4.839998\n",
      "Train Epoch: 3 [850/1457 (58%)]\tLoss: 4.189486\n",
      "Train Epoch: 3 [860/1457 (59%)]\tLoss: 4.128093\n",
      "Train Epoch: 3 [870/1457 (60%)]\tLoss: 4.622616\n",
      "Train Epoch: 3 [880/1457 (60%)]\tLoss: 4.173317\n",
      "Train Epoch: 3 [890/1457 (61%)]\tLoss: 4.075223\n",
      "Train Epoch: 3 [900/1457 (62%)]\tLoss: 3.907624\n",
      "Train Epoch: 3 [910/1457 (62%)]\tLoss: 3.794189\n",
      "Train Epoch: 3 [920/1457 (63%)]\tLoss: 4.200006\n",
      "Train Epoch: 3 [930/1457 (64%)]\tLoss: 4.090304\n",
      "Train Epoch: 3 [940/1457 (65%)]\tLoss: 4.252627\n",
      "Train Epoch: 3 [950/1457 (65%)]\tLoss: 3.891239\n",
      "Train Epoch: 3 [960/1457 (66%)]\tLoss: 4.353402\n",
      "Train Epoch: 3 [970/1457 (67%)]\tLoss: 3.835930\n",
      "Train Epoch: 3 [980/1457 (67%)]\tLoss: 3.911273\n",
      "Train Epoch: 3 [990/1457 (68%)]\tLoss: 3.851032\n",
      "Train Epoch: 3 [1000/1457 (69%)]\tLoss: 4.101084\n",
      "Train Epoch: 3 [1010/1457 (69%)]\tLoss: 4.328629\n",
      "Train Epoch: 3 [1020/1457 (70%)]\tLoss: 4.023299\n",
      "Train Epoch: 3 [1030/1457 (71%)]\tLoss: 3.835472\n",
      "Train Epoch: 3 [1040/1457 (71%)]\tLoss: 3.899921\n",
      "Train Epoch: 3 [1050/1457 (72%)]\tLoss: 4.165815\n",
      "Train Epoch: 3 [1060/1457 (73%)]\tLoss: 4.309572\n",
      "Train Epoch: 3 [1070/1457 (73%)]\tLoss: 3.773997\n",
      "Train Epoch: 3 [1080/1457 (74%)]\tLoss: 4.066352\n",
      "Train Epoch: 3 [1090/1457 (75%)]\tLoss: 4.203289\n",
      "Train Epoch: 3 [1100/1457 (75%)]\tLoss: 4.814880\n",
      "Train Epoch: 3 [1110/1457 (76%)]\tLoss: 4.322224\n",
      "Train Epoch: 3 [1120/1457 (77%)]\tLoss: 4.045772\n",
      "Train Epoch: 3 [1130/1457 (78%)]\tLoss: 4.039502\n",
      "Train Epoch: 3 [1140/1457 (78%)]\tLoss: 3.914158\n",
      "Train Epoch: 3 [1150/1457 (79%)]\tLoss: 4.150216\n",
      "Train Epoch: 3 [1160/1457 (80%)]\tLoss: 5.071296\n",
      "Train Epoch: 3 [1170/1457 (80%)]\tLoss: 4.594970\n",
      "Train Epoch: 3 [1180/1457 (81%)]\tLoss: 4.060222\n",
      "Train Epoch: 3 [1190/1457 (82%)]\tLoss: 4.145484\n",
      "Train Epoch: 3 [1200/1457 (82%)]\tLoss: 3.871495\n",
      "Train Epoch: 3 [1210/1457 (83%)]\tLoss: 4.049840\n",
      "Train Epoch: 3 [1220/1457 (84%)]\tLoss: 3.922284\n",
      "Train Epoch: 3 [1230/1457 (84%)]\tLoss: 3.781288\n",
      "Train Epoch: 3 [1240/1457 (85%)]\tLoss: 4.849117\n",
      "Train Epoch: 3 [1250/1457 (86%)]\tLoss: 4.099362\n",
      "Train Epoch: 3 [1260/1457 (86%)]\tLoss: 3.947948\n",
      "Train Epoch: 3 [1270/1457 (87%)]\tLoss: 4.389376\n",
      "Train Epoch: 3 [1280/1457 (88%)]\tLoss: 4.634772\n",
      "Train Epoch: 3 [1290/1457 (89%)]\tLoss: 3.793347\n",
      "Train Epoch: 3 [1300/1457 (89%)]\tLoss: 4.745325\n",
      "Train Epoch: 3 [1310/1457 (90%)]\tLoss: 3.786421\n",
      "Train Epoch: 3 [1320/1457 (91%)]\tLoss: 4.155637\n",
      "Train Epoch: 3 [1330/1457 (91%)]\tLoss: 4.259735\n",
      "Train Epoch: 3 [1340/1457 (92%)]\tLoss: 4.030581\n",
      "Train Epoch: 3 [1350/1457 (93%)]\tLoss: 3.955843\n",
      "Train Epoch: 3 [1360/1457 (93%)]\tLoss: 3.721016\n",
      "Train Epoch: 3 [1370/1457 (94%)]\tLoss: 4.365545\n",
      "Train Epoch: 3 [1380/1457 (95%)]\tLoss: 3.786950\n",
      "Train Epoch: 3 [1390/1457 (95%)]\tLoss: 4.043611\n",
      "Train Epoch: 3 [1400/1457 (96%)]\tLoss: 3.848689\n",
      "Train Epoch: 3 [1410/1457 (97%)]\tLoss: 3.762829\n",
      "Train Epoch: 3 [1420/1457 (97%)]\tLoss: 4.176706\n",
      "Train Epoch: 3 [1430/1457 (98%)]\tLoss: 3.934839\n",
      "Train Epoch: 3 [1440/1457 (99%)]\tLoss: 3.938578\n",
      "Train Epoch: 3 [1450/1457 (100%)]\tLoss: 4.356803\n",
      "====> Epoch: 3 Average loss: 4.1328\n",
      "Train Epoch: 4 [0/1457 (0%)]\tLoss: 3.876270\n",
      "Train Epoch: 4 [10/1457 (1%)]\tLoss: 4.206275\n",
      "Train Epoch: 4 [20/1457 (1%)]\tLoss: 4.139009\n",
      "Train Epoch: 4 [30/1457 (2%)]\tLoss: 4.041359\n",
      "Train Epoch: 4 [40/1457 (3%)]\tLoss: 3.849864\n",
      "Train Epoch: 4 [50/1457 (3%)]\tLoss: 6.018790\n",
      "Train Epoch: 4 [60/1457 (4%)]\tLoss: 4.570171\n",
      "Train Epoch: 4 [70/1457 (5%)]\tLoss: 4.498550\n",
      "Train Epoch: 4 [80/1457 (5%)]\tLoss: 4.176621\n",
      "Train Epoch: 4 [90/1457 (6%)]\tLoss: 4.171104\n",
      "Train Epoch: 4 [100/1457 (7%)]\tLoss: 3.973212\n",
      "Train Epoch: 4 [110/1457 (8%)]\tLoss: 3.903799\n",
      "Train Epoch: 4 [120/1457 (8%)]\tLoss: 3.902756\n",
      "Train Epoch: 4 [130/1457 (9%)]\tLoss: 4.319820\n",
      "Train Epoch: 4 [140/1457 (10%)]\tLoss: 3.988652\n",
      "Train Epoch: 4 [150/1457 (10%)]\tLoss: 4.234831\n",
      "Train Epoch: 4 [160/1457 (11%)]\tLoss: 4.425692\n",
      "Train Epoch: 4 [170/1457 (12%)]\tLoss: 4.394994\n",
      "Train Epoch: 4 [180/1457 (12%)]\tLoss: 4.093261\n",
      "Train Epoch: 4 [190/1457 (13%)]\tLoss: 3.997433\n",
      "Train Epoch: 4 [200/1457 (14%)]\tLoss: 3.957359\n",
      "Train Epoch: 4 [210/1457 (14%)]\tLoss: 4.224323\n",
      "Train Epoch: 4 [220/1457 (15%)]\tLoss: 4.711929\n",
      "Train Epoch: 4 [230/1457 (16%)]\tLoss: 4.132112\n",
      "Train Epoch: 4 [240/1457 (16%)]\tLoss: 4.391950\n",
      "Train Epoch: 4 [250/1457 (17%)]\tLoss: 4.161670\n",
      "Train Epoch: 4 [260/1457 (18%)]\tLoss: 3.990644\n",
      "Train Epoch: 4 [270/1457 (19%)]\tLoss: 4.310053\n",
      "Train Epoch: 4 [280/1457 (19%)]\tLoss: 4.210083\n",
      "Train Epoch: 4 [290/1457 (20%)]\tLoss: 3.814153\n",
      "Train Epoch: 4 [300/1457 (21%)]\tLoss: 4.337398\n",
      "Train Epoch: 4 [310/1457 (21%)]\tLoss: 3.861501\n",
      "Train Epoch: 4 [320/1457 (22%)]\tLoss: 4.894983\n",
      "Train Epoch: 4 [330/1457 (23%)]\tLoss: 3.842597\n",
      "Train Epoch: 4 [340/1457 (23%)]\tLoss: 4.013231\n",
      "Train Epoch: 4 [350/1457 (24%)]\tLoss: 4.210064\n",
      "Train Epoch: 4 [360/1457 (25%)]\tLoss: 4.091879\n",
      "Train Epoch: 4 [370/1457 (25%)]\tLoss: 3.896573\n",
      "Train Epoch: 4 [380/1457 (26%)]\tLoss: 4.150434\n",
      "Train Epoch: 4 [390/1457 (27%)]\tLoss: 3.745017\n",
      "Train Epoch: 4 [400/1457 (27%)]\tLoss: 4.171138\n",
      "Train Epoch: 4 [410/1457 (28%)]\tLoss: 4.889450\n",
      "Train Epoch: 4 [420/1457 (29%)]\tLoss: 4.669634\n",
      "Train Epoch: 4 [430/1457 (30%)]\tLoss: 3.990964\n",
      "Train Epoch: 4 [440/1457 (30%)]\tLoss: 3.891693\n",
      "Train Epoch: 4 [450/1457 (31%)]\tLoss: 3.982543\n",
      "Train Epoch: 4 [460/1457 (32%)]\tLoss: 3.668235\n",
      "Train Epoch: 4 [470/1457 (32%)]\tLoss: 4.044430\n",
      "Train Epoch: 4 [480/1457 (33%)]\tLoss: 3.863673\n",
      "Train Epoch: 4 [490/1457 (34%)]\tLoss: 3.731736\n",
      "Train Epoch: 4 [500/1457 (34%)]\tLoss: 3.874197\n",
      "Train Epoch: 4 [510/1457 (35%)]\tLoss: 4.305380\n",
      "Train Epoch: 4 [520/1457 (36%)]\tLoss: 4.375517\n",
      "Train Epoch: 4 [530/1457 (36%)]\tLoss: 4.093858\n",
      "Train Epoch: 4 [540/1457 (37%)]\tLoss: 4.639968\n",
      "Train Epoch: 4 [550/1457 (38%)]\tLoss: 4.376541\n",
      "Train Epoch: 4 [560/1457 (38%)]\tLoss: 3.878957\n",
      "Train Epoch: 4 [570/1457 (39%)]\tLoss: 3.828680\n",
      "Train Epoch: 4 [580/1457 (40%)]\tLoss: 4.050599\n",
      "Train Epoch: 4 [590/1457 (40%)]\tLoss: 4.128520\n",
      "Train Epoch: 4 [600/1457 (41%)]\tLoss: 3.841639\n",
      "Train Epoch: 4 [610/1457 (42%)]\tLoss: 3.922713\n",
      "Train Epoch: 4 [620/1457 (43%)]\tLoss: 3.491618\n",
      "Train Epoch: 4 [630/1457 (43%)]\tLoss: 3.771984\n",
      "Train Epoch: 4 [640/1457 (44%)]\tLoss: 3.930001\n",
      "Train Epoch: 4 [650/1457 (45%)]\tLoss: 4.017814\n",
      "Train Epoch: 4 [660/1457 (45%)]\tLoss: 4.389771\n",
      "Train Epoch: 4 [670/1457 (46%)]\tLoss: 4.278288\n",
      "Train Epoch: 4 [680/1457 (47%)]\tLoss: 3.999245\n",
      "Train Epoch: 4 [690/1457 (47%)]\tLoss: 4.123070\n",
      "Train Epoch: 4 [700/1457 (48%)]\tLoss: 3.974279\n",
      "Train Epoch: 4 [710/1457 (49%)]\tLoss: 3.964655\n",
      "Train Epoch: 4 [720/1457 (49%)]\tLoss: 5.350812\n",
      "Train Epoch: 4 [730/1457 (50%)]\tLoss: 4.423620\n",
      "Train Epoch: 4 [740/1457 (51%)]\tLoss: 3.822252\n",
      "Train Epoch: 4 [750/1457 (51%)]\tLoss: 3.919875\n",
      "Train Epoch: 4 [760/1457 (52%)]\tLoss: 4.391689\n",
      "Train Epoch: 4 [770/1457 (53%)]\tLoss: 3.915129\n",
      "Train Epoch: 4 [780/1457 (54%)]\tLoss: 3.781663\n",
      "Train Epoch: 4 [790/1457 (54%)]\tLoss: 4.301469\n",
      "Train Epoch: 4 [800/1457 (55%)]\tLoss: 4.618948\n",
      "Train Epoch: 4 [810/1457 (56%)]\tLoss: 4.330541\n",
      "Train Epoch: 4 [820/1457 (56%)]\tLoss: 4.208691\n",
      "Train Epoch: 4 [830/1457 (57%)]\tLoss: 3.816624\n",
      "Train Epoch: 4 [840/1457 (58%)]\tLoss: 4.920891\n",
      "Train Epoch: 4 [850/1457 (58%)]\tLoss: 4.142006\n",
      "Train Epoch: 4 [860/1457 (59%)]\tLoss: 4.205641\n",
      "Train Epoch: 4 [870/1457 (60%)]\tLoss: 5.153030\n",
      "Train Epoch: 4 [880/1457 (60%)]\tLoss: 4.123157\n",
      "Train Epoch: 4 [890/1457 (61%)]\tLoss: 4.490221\n",
      "Train Epoch: 4 [900/1457 (62%)]\tLoss: 3.728049\n",
      "Train Epoch: 4 [910/1457 (62%)]\tLoss: 3.845225\n",
      "Train Epoch: 4 [920/1457 (63%)]\tLoss: 4.064707\n",
      "Train Epoch: 4 [930/1457 (64%)]\tLoss: 3.958422\n",
      "Train Epoch: 4 [940/1457 (65%)]\tLoss: 4.048083\n",
      "Train Epoch: 4 [950/1457 (65%)]\tLoss: 3.995221\n",
      "Train Epoch: 4 [960/1457 (66%)]\tLoss: 4.130757\n",
      "Train Epoch: 4 [970/1457 (67%)]\tLoss: 4.076397\n",
      "Train Epoch: 4 [980/1457 (67%)]\tLoss: 3.931843\n",
      "Train Epoch: 4 [990/1457 (68%)]\tLoss: 3.773287\n",
      "Train Epoch: 4 [1000/1457 (69%)]\tLoss: 4.665620\n",
      "Train Epoch: 4 [1010/1457 (69%)]\tLoss: 4.303768\n",
      "Train Epoch: 4 [1020/1457 (70%)]\tLoss: 4.215651\n",
      "Train Epoch: 4 [1030/1457 (71%)]\tLoss: 3.895554\n",
      "Train Epoch: 4 [1040/1457 (71%)]\tLoss: 4.206940\n",
      "Train Epoch: 4 [1050/1457 (72%)]\tLoss: 3.940857\n",
      "Train Epoch: 4 [1060/1457 (73%)]\tLoss: 4.337039\n",
      "Train Epoch: 4 [1070/1457 (73%)]\tLoss: 3.954398\n",
      "Train Epoch: 4 [1080/1457 (74%)]\tLoss: 3.783948\n",
      "Train Epoch: 4 [1090/1457 (75%)]\tLoss: 4.153887\n",
      "Train Epoch: 4 [1100/1457 (75%)]\tLoss: 4.588313\n",
      "Train Epoch: 4 [1110/1457 (76%)]\tLoss: 4.256622\n",
      "Train Epoch: 4 [1120/1457 (77%)]\tLoss: 4.050638\n",
      "Train Epoch: 4 [1130/1457 (78%)]\tLoss: 4.063944\n",
      "Train Epoch: 4 [1140/1457 (78%)]\tLoss: 3.740665\n",
      "Train Epoch: 4 [1150/1457 (79%)]\tLoss: 4.131129\n",
      "Train Epoch: 4 [1160/1457 (80%)]\tLoss: 5.637056\n",
      "Train Epoch: 4 [1170/1457 (80%)]\tLoss: 4.042107\n",
      "Train Epoch: 4 [1180/1457 (81%)]\tLoss: 4.054990\n",
      "Train Epoch: 4 [1190/1457 (82%)]\tLoss: 4.157452\n",
      "Train Epoch: 4 [1200/1457 (82%)]\tLoss: 3.798246\n",
      "Train Epoch: 4 [1210/1457 (83%)]\tLoss: 4.111937\n",
      "Train Epoch: 4 [1220/1457 (84%)]\tLoss: 4.006266\n",
      "Train Epoch: 4 [1230/1457 (84%)]\tLoss: 3.896081\n",
      "Train Epoch: 4 [1240/1457 (85%)]\tLoss: 4.436082\n",
      "Train Epoch: 4 [1250/1457 (86%)]\tLoss: 3.928768\n",
      "Train Epoch: 4 [1260/1457 (86%)]\tLoss: 3.837103\n",
      "Train Epoch: 4 [1270/1457 (87%)]\tLoss: 4.332793\n",
      "Train Epoch: 4 [1280/1457 (88%)]\tLoss: 4.445691\n",
      "Train Epoch: 4 [1290/1457 (89%)]\tLoss: 3.766311\n",
      "Train Epoch: 4 [1300/1457 (89%)]\tLoss: 4.336659\n",
      "Train Epoch: 4 [1310/1457 (90%)]\tLoss: 3.762873\n",
      "Train Epoch: 4 [1320/1457 (91%)]\tLoss: 4.210088\n",
      "Train Epoch: 4 [1330/1457 (91%)]\tLoss: 4.438823\n",
      "Train Epoch: 4 [1340/1457 (92%)]\tLoss: 3.871578\n",
      "Train Epoch: 4 [1350/1457 (93%)]\tLoss: 3.785835\n",
      "Train Epoch: 4 [1360/1457 (93%)]\tLoss: 3.981488\n",
      "Train Epoch: 4 [1370/1457 (94%)]\tLoss: 4.186462\n",
      "Train Epoch: 4 [1380/1457 (95%)]\tLoss: 3.801606\n",
      "Train Epoch: 4 [1390/1457 (95%)]\tLoss: 4.099863\n",
      "Train Epoch: 4 [1400/1457 (96%)]\tLoss: 3.829510\n",
      "Train Epoch: 4 [1410/1457 (97%)]\tLoss: 3.819823\n",
      "Train Epoch: 4 [1420/1457 (97%)]\tLoss: 4.290118\n",
      "Train Epoch: 4 [1430/1457 (98%)]\tLoss: 4.079010\n",
      "Train Epoch: 4 [1440/1457 (99%)]\tLoss: 3.879288\n",
      "Train Epoch: 4 [1450/1457 (100%)]\tLoss: 4.228891\n",
      "====> Epoch: 4 Average loss: 4.1310\n",
      "Train Epoch: 5 [0/1457 (0%)]\tLoss: 4.101336\n",
      "Train Epoch: 5 [10/1457 (1%)]\tLoss: 4.107768\n",
      "Train Epoch: 5 [20/1457 (1%)]\tLoss: 4.000623\n",
      "Train Epoch: 5 [30/1457 (2%)]\tLoss: 3.908332\n",
      "Train Epoch: 5 [40/1457 (3%)]\tLoss: 3.757933\n",
      "Train Epoch: 5 [50/1457 (3%)]\tLoss: 5.672764\n",
      "Train Epoch: 5 [60/1457 (4%)]\tLoss: 4.253539\n",
      "Train Epoch: 5 [70/1457 (5%)]\tLoss: 4.722366\n",
      "Train Epoch: 5 [80/1457 (5%)]\tLoss: 4.084410\n",
      "Train Epoch: 5 [90/1457 (6%)]\tLoss: 4.053133\n",
      "Train Epoch: 5 [100/1457 (7%)]\tLoss: 3.948869\n",
      "Train Epoch: 5 [110/1457 (8%)]\tLoss: 3.876921\n",
      "Train Epoch: 5 [120/1457 (8%)]\tLoss: 3.969912\n",
      "Train Epoch: 5 [130/1457 (9%)]\tLoss: 4.248318\n",
      "Train Epoch: 5 [140/1457 (10%)]\tLoss: 4.041909\n",
      "Train Epoch: 5 [150/1457 (10%)]\tLoss: 3.983333\n",
      "Train Epoch: 5 [160/1457 (11%)]\tLoss: 4.387617\n",
      "Train Epoch: 5 [170/1457 (12%)]\tLoss: 4.828830\n",
      "Train Epoch: 5 [180/1457 (12%)]\tLoss: 3.877755\n",
      "Train Epoch: 5 [190/1457 (13%)]\tLoss: 3.911449\n",
      "Train Epoch: 5 [200/1457 (14%)]\tLoss: 3.839472\n",
      "Train Epoch: 5 [210/1457 (14%)]\tLoss: 4.197835\n",
      "Train Epoch: 5 [220/1457 (15%)]\tLoss: 4.469790\n",
      "Train Epoch: 5 [230/1457 (16%)]\tLoss: 4.415739\n",
      "Train Epoch: 5 [240/1457 (16%)]\tLoss: 4.490214\n",
      "Train Epoch: 5 [250/1457 (17%)]\tLoss: 3.956812\n",
      "Train Epoch: 5 [260/1457 (18%)]\tLoss: 3.814521\n",
      "Train Epoch: 5 [270/1457 (19%)]\tLoss: 4.504021\n",
      "Train Epoch: 5 [280/1457 (19%)]\tLoss: 4.087337\n",
      "Train Epoch: 5 [290/1457 (20%)]\tLoss: 3.733164\n",
      "Train Epoch: 5 [300/1457 (21%)]\tLoss: 4.226875\n",
      "Train Epoch: 5 [310/1457 (21%)]\tLoss: 3.953620\n",
      "Train Epoch: 5 [320/1457 (22%)]\tLoss: 4.951367\n",
      "Train Epoch: 5 [330/1457 (23%)]\tLoss: 3.925041\n",
      "Train Epoch: 5 [340/1457 (23%)]\tLoss: 3.876626\n",
      "Train Epoch: 5 [350/1457 (24%)]\tLoss: 4.631575\n",
      "Train Epoch: 5 [360/1457 (25%)]\tLoss: 4.189391\n",
      "Train Epoch: 5 [370/1457 (25%)]\tLoss: 4.137820\n",
      "Train Epoch: 5 [380/1457 (26%)]\tLoss: 4.005535\n",
      "Train Epoch: 5 [390/1457 (27%)]\tLoss: 4.047207\n",
      "Train Epoch: 5 [400/1457 (27%)]\tLoss: 4.675033\n",
      "Train Epoch: 5 [410/1457 (28%)]\tLoss: 4.362144\n",
      "Train Epoch: 5 [420/1457 (29%)]\tLoss: 4.399047\n",
      "Train Epoch: 5 [430/1457 (30%)]\tLoss: 3.916559\n",
      "Train Epoch: 5 [440/1457 (30%)]\tLoss: 4.025956\n",
      "Train Epoch: 5 [450/1457 (31%)]\tLoss: 3.901179\n",
      "Train Epoch: 5 [460/1457 (32%)]\tLoss: 3.821943\n",
      "Train Epoch: 5 [470/1457 (32%)]\tLoss: 3.986342\n",
      "Train Epoch: 5 [480/1457 (33%)]\tLoss: 3.890177\n",
      "Train Epoch: 5 [490/1457 (34%)]\tLoss: 3.691103\n",
      "Train Epoch: 5 [500/1457 (34%)]\tLoss: 3.819829\n",
      "Train Epoch: 5 [510/1457 (35%)]\tLoss: 4.316676\n",
      "Train Epoch: 5 [520/1457 (36%)]\tLoss: 4.170039\n",
      "Train Epoch: 5 [530/1457 (36%)]\tLoss: 3.809640\n",
      "Train Epoch: 5 [540/1457 (37%)]\tLoss: 4.395750\n",
      "Train Epoch: 5 [550/1457 (38%)]\tLoss: 4.673470\n",
      "Train Epoch: 5 [560/1457 (38%)]\tLoss: 3.736378\n",
      "Train Epoch: 5 [570/1457 (39%)]\tLoss: 3.809313\n",
      "Train Epoch: 5 [580/1457 (40%)]\tLoss: 4.072325\n",
      "Train Epoch: 5 [590/1457 (40%)]\tLoss: 3.856117\n",
      "Train Epoch: 5 [600/1457 (41%)]\tLoss: 3.907296\n",
      "Train Epoch: 5 [610/1457 (42%)]\tLoss: 3.886104\n",
      "Train Epoch: 5 [620/1457 (43%)]\tLoss: 3.649136\n",
      "Train Epoch: 5 [630/1457 (43%)]\tLoss: 3.873696\n",
      "Train Epoch: 5 [640/1457 (44%)]\tLoss: 3.701226\n",
      "Train Epoch: 5 [650/1457 (45%)]\tLoss: 3.781493\n",
      "Train Epoch: 5 [660/1457 (45%)]\tLoss: 4.504742\n",
      "Train Epoch: 5 [670/1457 (46%)]\tLoss: 4.306147\n",
      "Train Epoch: 5 [680/1457 (47%)]\tLoss: 3.900834\n",
      "Train Epoch: 5 [690/1457 (47%)]\tLoss: 4.045699\n",
      "Train Epoch: 5 [700/1457 (48%)]\tLoss: 3.977983\n",
      "Train Epoch: 5 [710/1457 (49%)]\tLoss: 3.960149\n",
      "Train Epoch: 5 [720/1457 (49%)]\tLoss: 4.756195\n",
      "Train Epoch: 5 [730/1457 (50%)]\tLoss: 4.937321\n",
      "Train Epoch: 5 [740/1457 (51%)]\tLoss: 4.040895\n",
      "Train Epoch: 5 [750/1457 (51%)]\tLoss: 3.962798\n",
      "Train Epoch: 5 [760/1457 (52%)]\tLoss: 4.422863\n",
      "Train Epoch: 5 [770/1457 (53%)]\tLoss: 3.852314\n",
      "Train Epoch: 5 [780/1457 (54%)]\tLoss: 3.784580\n",
      "Train Epoch: 5 [790/1457 (54%)]\tLoss: 4.161684\n",
      "Train Epoch: 5 [800/1457 (55%)]\tLoss: 4.154823\n",
      "Train Epoch: 5 [810/1457 (56%)]\tLoss: 4.349897\n",
      "Train Epoch: 5 [820/1457 (56%)]\tLoss: 4.285129\n",
      "Train Epoch: 5 [830/1457 (57%)]\tLoss: 3.836437\n",
      "Train Epoch: 5 [840/1457 (58%)]\tLoss: 4.440269\n",
      "Train Epoch: 5 [850/1457 (58%)]\tLoss: 4.173674\n",
      "Train Epoch: 5 [860/1457 (59%)]\tLoss: 4.133121\n",
      "Train Epoch: 5 [870/1457 (60%)]\tLoss: 4.336117\n",
      "Train Epoch: 5 [880/1457 (60%)]\tLoss: 3.870811\n",
      "Train Epoch: 5 [890/1457 (61%)]\tLoss: 4.286662\n",
      "Train Epoch: 5 [900/1457 (62%)]\tLoss: 3.710253\n",
      "Train Epoch: 5 [910/1457 (62%)]\tLoss: 3.950579\n",
      "Train Epoch: 5 [920/1457 (63%)]\tLoss: 4.174053\n",
      "Train Epoch: 5 [930/1457 (64%)]\tLoss: 4.053000\n",
      "Train Epoch: 5 [940/1457 (65%)]\tLoss: 4.296889\n",
      "Train Epoch: 5 [950/1457 (65%)]\tLoss: 3.988442\n",
      "Train Epoch: 5 [960/1457 (66%)]\tLoss: 4.219159\n",
      "Train Epoch: 5 [970/1457 (67%)]\tLoss: 4.025253\n",
      "Train Epoch: 5 [980/1457 (67%)]\tLoss: 3.814586\n",
      "Train Epoch: 5 [990/1457 (68%)]\tLoss: 3.766436\n",
      "Train Epoch: 5 [1000/1457 (69%)]\tLoss: 3.934340\n",
      "Train Epoch: 5 [1010/1457 (69%)]\tLoss: 4.314071\n",
      "Train Epoch: 5 [1020/1457 (70%)]\tLoss: 4.374172\n",
      "Train Epoch: 5 [1030/1457 (71%)]\tLoss: 3.710666\n",
      "Train Epoch: 5 [1040/1457 (71%)]\tLoss: 3.783296\n",
      "Train Epoch: 5 [1050/1457 (72%)]\tLoss: 3.943347\n",
      "Train Epoch: 5 [1060/1457 (73%)]\tLoss: 4.262244\n",
      "Train Epoch: 5 [1070/1457 (73%)]\tLoss: 3.784884\n",
      "Train Epoch: 5 [1080/1457 (74%)]\tLoss: 3.895987\n",
      "Train Epoch: 5 [1090/1457 (75%)]\tLoss: 4.106368\n",
      "Train Epoch: 5 [1100/1457 (75%)]\tLoss: 4.817720\n",
      "Train Epoch: 5 [1110/1457 (76%)]\tLoss: 4.205676\n",
      "Train Epoch: 5 [1120/1457 (77%)]\tLoss: 3.929758\n",
      "Train Epoch: 5 [1130/1457 (78%)]\tLoss: 4.068449\n",
      "Train Epoch: 5 [1140/1457 (78%)]\tLoss: 3.793277\n",
      "Train Epoch: 5 [1150/1457 (79%)]\tLoss: 3.966209\n",
      "Train Epoch: 5 [1160/1457 (80%)]\tLoss: 5.080632\n",
      "Train Epoch: 5 [1170/1457 (80%)]\tLoss: 4.086608\n",
      "Train Epoch: 5 [1180/1457 (81%)]\tLoss: 3.985859\n",
      "Train Epoch: 5 [1190/1457 (82%)]\tLoss: 4.222874\n",
      "Train Epoch: 5 [1200/1457 (82%)]\tLoss: 3.777521\n",
      "Train Epoch: 5 [1210/1457 (83%)]\tLoss: 4.069446\n",
      "Train Epoch: 5 [1220/1457 (84%)]\tLoss: 3.976749\n",
      "Train Epoch: 5 [1230/1457 (84%)]\tLoss: 3.609520\n",
      "Train Epoch: 5 [1240/1457 (85%)]\tLoss: 4.322587\n",
      "Train Epoch: 5 [1250/1457 (86%)]\tLoss: 3.834139\n",
      "Train Epoch: 5 [1260/1457 (86%)]\tLoss: 3.987265\n",
      "Train Epoch: 5 [1270/1457 (87%)]\tLoss: 4.401489\n",
      "Train Epoch: 5 [1280/1457 (88%)]\tLoss: 4.394038\n",
      "Train Epoch: 5 [1290/1457 (89%)]\tLoss: 3.853127\n",
      "Train Epoch: 5 [1300/1457 (89%)]\tLoss: 4.360352\n",
      "Train Epoch: 5 [1310/1457 (90%)]\tLoss: 3.756368\n",
      "Train Epoch: 5 [1320/1457 (91%)]\tLoss: 4.297444\n",
      "Train Epoch: 5 [1330/1457 (91%)]\tLoss: 4.452944\n",
      "Train Epoch: 5 [1340/1457 (92%)]\tLoss: 4.254586\n",
      "Train Epoch: 5 [1350/1457 (93%)]\tLoss: 3.880384\n",
      "Train Epoch: 5 [1360/1457 (93%)]\tLoss: 3.809786\n",
      "Train Epoch: 5 [1370/1457 (94%)]\tLoss: 3.932766\n",
      "Train Epoch: 5 [1380/1457 (95%)]\tLoss: 3.771947\n",
      "Train Epoch: 5 [1390/1457 (95%)]\tLoss: 4.086739\n",
      "Train Epoch: 5 [1400/1457 (96%)]\tLoss: 3.906309\n",
      "Train Epoch: 5 [1410/1457 (97%)]\tLoss: 3.833939\n",
      "Train Epoch: 5 [1420/1457 (97%)]\tLoss: 4.135331\n",
      "Train Epoch: 5 [1430/1457 (98%)]\tLoss: 4.194138\n",
      "Train Epoch: 5 [1440/1457 (99%)]\tLoss: 3.605423\n",
      "Train Epoch: 5 [1450/1457 (100%)]\tLoss: 4.195654\n",
      "====> Epoch: 5 Average loss: 4.1207\n",
      "Peeking Type <class 'numpy.ndarray'>\n",
      "(29302, 8) (29302,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from launchpad import VAEify \n",
    "\n",
    "X_vae,y_vae=VAEify(X_train,y_train)\n",
    "\n",
    "logreg.fit(X_vae,y_vae)\n",
    "\n",
    "y_pred_vae=logreg.predict(X_test)\n",
    "\n",
    "score_vae=roc_auc_score(y_pred_vae,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>WGAN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7560/7560] LG:0.509 LD:-0.134 D:-0.020 GP:0.008 AC: 0.361 RMSEAVG:0.296 NUM:0.257 SynTraiAuc:0.076 RFAcc:1.000   \n"
     ]
    }
   ],
   "source": [
    "from launchpad import WGANify\n",
    "\n",
    "X_wgan,y_wgan=WGANify(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_wgan,y_wgan)\n",
    "\n",
    "y_pred_wgan=logreg.predict(X_test)\n",
    "\n",
    "score_wgan=roc_auc_score(y_pred_wgan,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_pred_wgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> SMOTE </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pigeon/Downloads/yes/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "logreg.fit(X_smote,y_smote)\n",
    "\n",
    "y_pred_smote=logreg.predict(X_test)\n",
    "\n",
    "score_smote=roc_auc_score(y_pred_smote,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5809d96ab6c2bcc5e68a08c20050b18c36db3ca8e55d204f37a00fefc825d8b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
